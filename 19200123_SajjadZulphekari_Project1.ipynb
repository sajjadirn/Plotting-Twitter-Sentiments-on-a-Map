{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Sajjad Zulphekari (19200123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the necessary packages for data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json # The API returns JSON formatted text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Selecting the appropriate API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to choose the Twitter API for this project\n",
    "\n",
    "Twitter API requires 4 Keys for authentication which can be generated by creating a Developers account in twitter\n",
    "\n",
    "As the keys are meant to be private and are assigned to my personal account, I have kept the keys field blank, to test this out, you can use your own private key\n",
    "\n",
    "You can continue running from Step 3 as I have collected the tweets and submitted it along with this notebook and you dont have to perfrom the collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing the API keys and Tokens required for the Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token='' #your access token\n",
    "access_token_secret='' #your access token secret\n",
    "consumer_key='' #your consumer key\n",
    "consumer_secret='' # your consumer secret "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the keys and tokens for authenticating the the API as mentioned in the tweepy documentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweepy Documentation for authentication:  http://docs.tweepy.org/en/latest/auth_tutorial.html\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Collection of tweets from the Twitter API and Storage in a File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Initializing the specific keyword we want the tweets to contain, the output text file where the tweets will be stored and the number of tweets to be collected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACKING_KEYWORDS = ['coronavirus'] #Since we want to only collect the tweets which have the term coronavirus in them, \n",
    "                                    #we mention that keyword here\n",
    "OUTPUT_FILE = \"corona_tweets.txt\"  #Output will be in a json structured format stored as a txt file\n",
    "TWEETS_TO_CAPTURE = 10000          #Initiazlizing the number of tweets to capture "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Twitter Streamer Class where the tweets will be streamed and collected\n",
    "#####            Making changes in the predefined StreamerListener class in tweepy by inheriting it so that we can store the streamed tweets in a file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    \"\"\"\n",
    "    Twitter listener, collects streaming tweets and output to a file\n",
    "    \"\"\"\n",
    "    def __init__(self, api=None):#defining a _init__ object to initialize the variables \n",
    "        super(MyStreamListener, self).__init__()\n",
    "        self.num_tweets = 0\n",
    "        self.file = open(OUTPUT_FILE, \"w\")\n",
    "\n",
    "    def on_status(self, status): #making changes to on_status function in the StreamListener class inherited from tweepy\n",
    "        tweet = status._json #storing one tweet at a time in the variable tweet\n",
    "        self.file.write( json.dumps(tweet) + '\\n' ) #Writing the tweet in a file and appending \\n to it so that new tweets go to the next line\n",
    "        self.num_tweets += 1 #incrementing the number of tweets collected \n",
    "        \n",
    "        \n",
    "        if self.num_tweets <= TWEETS_TO_CAPTURE: #using if statement to check the total number of tweets captured \n",
    "            if self.num_tweets % 100 == 0: # using this if statement to print the number of tweets captured in the intervals of 100\n",
    "                print('Numer of tweets captured so far: {}'.format(self.num_tweets))\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        self.file.close() #closing the file once the required number of tweets have been captured \n",
    "\n",
    "    def on_error(self, status): #using the predefined on_error function in streamlistener class to print errors in case of any errors \n",
    "        print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Initializing StreamListener and collecting the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = MyStreamListener() #Initializing the StreamListener \n",
    "\n",
    "stream = tweepy.Stream(auth, sl) # Creating a stream object with authentication \n",
    "\n",
    "# Filter Twitter Streams to capture data by the keywords:\n",
    "stream.filter(track=TRACKING_KEYWORDS, languages = ['en']) #Using the inbuilt filter class to collect the tweets based on keywords\n",
    "#Here the parameters are track where we send the keyword we want each tweet to contain and languages where we send the langague we want the tweets to be in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Reading the file which has the collected tweets and  storing it in a list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Reading the tweets from the stored file and storing it in a list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data = [] #Initializing an empty list to store the tweets from the file where the tweets are saved \n",
    "\n",
    "# Opening the file where the tweets are stored \n",
    "with open(\"corona_tweets.txt\", \"r\") as tweets_file:\n",
    "    for line in tweets_file: #Reading each line from the file which is one single tweet and storing it in the list\n",
    "        tweet = json.loads(line)\n",
    "        tweets_data.append(tweet) #appending each tweet to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': 'Tue Mar 10 11:57:04 +0000 2020',\n",
       " 'id': 1237346732159139842,\n",
       " 'id_str': '1237346732159139842',\n",
       " 'text': 'RT @debornair99: La Liga Santander confirm their next two rounds of fixtures will be played behind closed doors due to the coronavirus outb‚Ä¶',\n",
       " 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       " 'truncated': False,\n",
       " 'in_reply_to_status_id': None,\n",
       " 'in_reply_to_status_id_str': None,\n",
       " 'in_reply_to_user_id': None,\n",
       " 'in_reply_to_user_id_str': None,\n",
       " 'in_reply_to_screen_name': None,\n",
       " 'user': {'id': 593638590,\n",
       "  'id_str': '593638590',\n",
       "  'name': 'senr_marlianüá≥üá¨',\n",
       "  'screen_name': 'bamzyosho',\n",
       "  'location': 'Ikeja, Nigeria',\n",
       "  'url': None,\n",
       "  'description': 'E-zero belt a thousand trousers...ü§∑üèº\\u200d‚ôÇÔ∏è ü§°',\n",
       "  'translator_type': 'none',\n",
       "  'protected': False,\n",
       "  'verified': False,\n",
       "  'followers_count': 711,\n",
       "  'friends_count': 600,\n",
       "  'listed_count': 0,\n",
       "  'favourites_count': 3114,\n",
       "  'statuses_count': 7997,\n",
       "  'created_at': 'Tue May 29 09:48:42 +0000 2012',\n",
       "  'utc_offset': None,\n",
       "  'time_zone': None,\n",
       "  'geo_enabled': False,\n",
       "  'lang': None,\n",
       "  'contributors_enabled': False,\n",
       "  'is_translator': False,\n",
       "  'profile_background_color': 'C0DEED',\n",
       "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_tile': False,\n",
       "  'profile_link_color': '1DA1F2',\n",
       "  'profile_sidebar_border_color': 'C0DEED',\n",
       "  'profile_sidebar_fill_color': 'DDEEF6',\n",
       "  'profile_text_color': '333333',\n",
       "  'profile_use_background_image': True,\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/1228635502657572865/MRwzGdgG_normal.jpg',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1228635502657572865/MRwzGdgG_normal.jpg',\n",
       "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/593638590/1582825959',\n",
       "  'default_profile': True,\n",
       "  'default_profile_image': False,\n",
       "  'following': None,\n",
       "  'follow_request_sent': None,\n",
       "  'notifications': None},\n",
       " 'geo': None,\n",
       " 'coordinates': None,\n",
       " 'place': None,\n",
       " 'contributors': None,\n",
       " 'retweeted_status': {'created_at': 'Tue Mar 10 11:28:20 +0000 2020',\n",
       "  'id': 1237339501816680448,\n",
       "  'id_str': '1237339501816680448',\n",
       "  'text': 'La Liga Santander confirm their next two rounds of fixtures will be played behind closed doors due to the coronavir‚Ä¶ https://t.co/afvm9Dr5c4',\n",
       "  'display_text_range': [0, 140],\n",
       "  'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       "  'truncated': True,\n",
       "  'in_reply_to_status_id': None,\n",
       "  'in_reply_to_status_id_str': None,\n",
       "  'in_reply_to_user_id': None,\n",
       "  'in_reply_to_user_id_str': None,\n",
       "  'in_reply_to_screen_name': None,\n",
       "  'user': {'id': 3362807435,\n",
       "   'id_str': '3362807435',\n",
       "   'name': \"De'bowale Osho\",\n",
       "   'screen_name': 'debornair99',\n",
       "   'location': 'Lagos, Nigeria',\n",
       "   'url': 'https://soundcloud.com/israelvista/jimmy-butler-aj-champions-league',\n",
       "   'description': 'Co-founder @thesportpodcast | Sportscaster @unilagfm_103.1 | Aspiring Sport Analyst üë®üèæ\\u200düíº | Operations Support Personnel.Visit @thesportpodcast üéô for updates',\n",
       "   'translator_type': 'none',\n",
       "   'protected': False,\n",
       "   'verified': False,\n",
       "   'followers_count': 3088,\n",
       "   'friends_count': 1362,\n",
       "   'listed_count': 5,\n",
       "   'favourites_count': 3594,\n",
       "   'statuses_count': 39346,\n",
       "   'created_at': 'Mon Jul 06 18:07:34 +0000 2015',\n",
       "   'utc_offset': None,\n",
       "   'time_zone': None,\n",
       "   'geo_enabled': True,\n",
       "   'lang': None,\n",
       "   'contributors_enabled': False,\n",
       "   'is_translator': False,\n",
       "   'profile_background_color': '000000',\n",
       "   'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "   'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "   'profile_background_tile': False,\n",
       "   'profile_link_color': 'FF691F',\n",
       "   'profile_sidebar_border_color': '000000',\n",
       "   'profile_sidebar_fill_color': '000000',\n",
       "   'profile_text_color': '000000',\n",
       "   'profile_use_background_image': False,\n",
       "   'profile_image_url': 'http://pbs.twimg.com/profile_images/1237313493285683200/WegzWOqG_normal.jpg',\n",
       "   'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1237313493285683200/WegzWOqG_normal.jpg',\n",
       "   'profile_banner_url': 'https://pbs.twimg.com/profile_banners/3362807435/1583833433',\n",
       "   'default_profile': False,\n",
       "   'default_profile_image': False,\n",
       "   'following': None,\n",
       "   'follow_request_sent': None,\n",
       "   'notifications': None},\n",
       "  'geo': None,\n",
       "  'coordinates': None,\n",
       "  'place': None,\n",
       "  'contributors': None,\n",
       "  'is_quote_status': False,\n",
       "  'extended_tweet': {'full_text': 'La Liga Santander confirm their next two rounds of fixtures will be played behind closed doors due to the coronavirus outbreak üò∑ https://t.co/ctL5AR3JJT',\n",
       "   'display_text_range': [0, 128],\n",
       "   'entities': {'hashtags': [],\n",
       "    'urls': [],\n",
       "    'user_mentions': [],\n",
       "    'symbols': [],\n",
       "    'media': [{'id': 1237339487858044930,\n",
       "      'id_str': '1237339487858044930',\n",
       "      'indices': [129, 152],\n",
       "      'media_url': 'http://pbs.twimg.com/media/ESvptWBXsAIIEyJ.jpg',\n",
       "      'media_url_https': 'https://pbs.twimg.com/media/ESvptWBXsAIIEyJ.jpg',\n",
       "      'url': 'https://t.co/ctL5AR3JJT',\n",
       "      'display_url': 'pic.twitter.com/ctL5AR3JJT',\n",
       "      'expanded_url': 'https://twitter.com/debornair99/status/1237339501816680448/photo/1',\n",
       "      'type': 'photo',\n",
       "      'sizes': {'thumb': {'w': 150, 'h': 150, 'resize': 'crop'},\n",
       "       'large': {'w': 2047, 'h': 1264, 'resize': 'fit'},\n",
       "       'medium': {'w': 1200, 'h': 741, 'resize': 'fit'},\n",
       "       'small': {'w': 680, 'h': 420, 'resize': 'fit'}}}]},\n",
       "   'extended_entities': {'media': [{'id': 1237339487858044930,\n",
       "      'id_str': '1237339487858044930',\n",
       "      'indices': [129, 152],\n",
       "      'media_url': 'http://pbs.twimg.com/media/ESvptWBXsAIIEyJ.jpg',\n",
       "      'media_url_https': 'https://pbs.twimg.com/media/ESvptWBXsAIIEyJ.jpg',\n",
       "      'url': 'https://t.co/ctL5AR3JJT',\n",
       "      'display_url': 'pic.twitter.com/ctL5AR3JJT',\n",
       "      'expanded_url': 'https://twitter.com/debornair99/status/1237339501816680448/photo/1',\n",
       "      'type': 'photo',\n",
       "      'sizes': {'thumb': {'w': 150, 'h': 150, 'resize': 'crop'},\n",
       "       'large': {'w': 2047, 'h': 1264, 'resize': 'fit'},\n",
       "       'medium': {'w': 1200, 'h': 741, 'resize': 'fit'},\n",
       "       'small': {'w': 680, 'h': 420, 'resize': 'fit'}}}]}},\n",
       "  'quote_count': 0,\n",
       "  'reply_count': 0,\n",
       "  'retweet_count': 3,\n",
       "  'favorite_count': 5,\n",
       "  'entities': {'hashtags': [],\n",
       "   'urls': [{'url': 'https://t.co/afvm9Dr5c4',\n",
       "     'expanded_url': 'https://twitter.com/i/web/status/1237339501816680448',\n",
       "     'display_url': 'twitter.com/i/web/status/1‚Ä¶',\n",
       "     'indices': [117, 140]}],\n",
       "   'user_mentions': [],\n",
       "   'symbols': []},\n",
       "  'favorited': False,\n",
       "  'retweeted': False,\n",
       "  'possibly_sensitive': False,\n",
       "  'filter_level': 'low',\n",
       "  'lang': 'en'},\n",
       " 'is_quote_status': False,\n",
       " 'quote_count': 0,\n",
       " 'reply_count': 0,\n",
       " 'retweet_count': 0,\n",
       " 'favorite_count': 0,\n",
       " 'entities': {'hashtags': [],\n",
       "  'urls': [],\n",
       "  'user_mentions': [{'screen_name': 'debornair99',\n",
       "    'name': \"De'bowale Osho\",\n",
       "    'id': 3362807435,\n",
       "    'id_str': '3362807435',\n",
       "    'indices': [3, 15]}],\n",
       "  'symbols': []},\n",
       " 'favorited': False,\n",
       " 'retweeted': False,\n",
       " 'filter_level': 'low',\n",
       " 'lang': 'en',\n",
       " 'timestamp_ms': '1583841424394'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_data[0] #printing a sample tweet to show how it is stored in a file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Loading and representing the tweets in a DataFrame.\n",
    "## Applying any pre-processing steps to clean/filter/combine the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for this analysis we only need the actual tweet and the location of the user profile, we only select those values from the tweets_data which is a list of dictonaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Filtering the required data from the tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(columns=['location', 'text']) #Initializing the DataFrame with two columns\n",
    "location = [] #Empty list where we will append the user location from all the tweets in the tweets_data list\n",
    "text = [] #Empty list where we will append the actual tweet from all the tweets in the tweets_data list\n",
    "for tweet in tweets_data: #Iterating through every tweet in tweets_data\n",
    "     #Using the .get syntax to collect the required data from the the list\n",
    "    location.append(tweet.get('user', {}).get('location', {})) #As the location of the user is under the user, \n",
    "    #we first extract the user and then from that we extract the location of that user and append it to the list\n",
    "    text.append(tweet.get('text', {})) # Extracing the actual tweet text and appending it to the list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Storing the tweets in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Ikeja, Nigeria</td>\n",
       "      <td>RT @debornair99: La Liga Santander confirm the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>RT @TheJessieWoo: White folks really upset tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Earth</td>\n",
       "      <td>RT @nycjim: CDC tells people over 60 or who ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Biogen, Eli Lilly, Takeda ask staff to work fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>RT @hilaryluros: It‚Äôs America‚Äôs Coronavirus no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>ƒ∞stanbul, T√ºrkiye</td>\n",
       "      <td>RT @MustardV3VO: AYO DID THIS NIGGA WATERMARK ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>None</td>\n",
       "      <td>RT @LASK_eng: Statement from the @OEFBL statin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>Medfield MA</td>\n",
       "      <td>RT @dbongino: If you‚Äôre looking for hysterical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>None</td>\n",
       "      <td>RT @COVID_19_News: The situation in Italian pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>United States</td>\n",
       "      <td>RT @GovMikeHuckabee: It takes a special kind o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10001 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                location                                               text\n",
       "0         Ikeja, Nigeria  RT @debornair99: La Liga Santander confirm the...\n",
       "1                   None  RT @TheJessieWoo: White folks really upset tha...\n",
       "2                  Earth  RT @nycjim: CDC tells people over 60 or who ha...\n",
       "3            Puerto Rico  Biogen, Eli Lilly, Takeda ask staff to work fr...\n",
       "4                   None  RT @hilaryluros: It‚Äôs America‚Äôs Coronavirus no...\n",
       "...                  ...                                                ...\n",
       "9996   ƒ∞stanbul, T√ºrkiye  RT @MustardV3VO: AYO DID THIS NIGGA WATERMARK ...\n",
       "9997                None  RT @LASK_eng: Statement from the @OEFBL statin...\n",
       "9998         Medfield MA  RT @dbongino: If you‚Äôre looking for hysterical...\n",
       "9999                None  RT @COVID_19_News: The situation in Italian pr...\n",
       "10000      United States  RT @GovMikeHuckabee: It takes a special kind o...\n",
       "\n",
       "[10001 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['location'] = location #Storing each tweet location in the location column in the dataframe\n",
    "df1['text'] = text  #Storing each tweet text in the text column in the dataframe\n",
    "df1 #Printing the current df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Data cleaning \n",
    "As the location field doesnt always have a value, we will find the number of None values and delete them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3202"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['location'].isna().sum() #Finding total number of null values in location column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.replace(to_replace='None', value=np.nan).dropna() #Replacing the rows which have 'None' in them with nan and then deleting them using dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['location'].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[~df1.text.str.startswith('RT @')] #For this analysis we dont need tweets which have been retweeted\n",
    "                                            #So we remove all the tweets which begin with RT @ (Which is how Retweets begin in the twitter data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Data Pre-Processing \n",
    "I have decided to use the named location of each user, convert them into coordinates and then plot it on the map, to see where the users are tweeting from about coronavirus.\n",
    "\n",
    "For this we will use the geopy package which includes a geocoder function which returns the coordinates of the Named locations\n",
    "\n",
    "For example if the input is New York, geopy will return (40.7410861, -73.9896297241625) which are its coordinates \n",
    "\n",
    "Documentation: https://pypi.org/project/geopy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary packages \n",
    "import geopy\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "# As we are geocoding a large number of location,the geocoder might deny the request\n",
    "# So We import the RateLimiter so that we can delay the requests sent to the geocoder(Nominatim) between every request\n",
    "from  geopy.geocoders import Nominatim\n",
    "locator = Nominatim(user_agent='geocode') #Initializing the Nominatim geocoder as the geocoder\n",
    "geocode = RateLimiter(locator.geocode, min_delay_seconds=1) #Assigning a delay of 1 sec between each call to the geocoder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block will take a long time to finish with the execution, So I have executed the code for the whole dataframe nad stored it in a CSV file named cleanedlocations.csv and submitted that along with the notebook. \n",
    "\n",
    "I have read this CSV file in the Step 5 and performed further analysis\n",
    "\n",
    "If you want to test the code, I have created a small sample of df1 with 10 values which you can execute.\n",
    "\n",
    "If you still want to run it for the whole dataframe, remove .head(n=10) from the next block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dftest = df1.head(n=10) #optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('Puerto Rico',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1317, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1244, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1290, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1239, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1414, in connect\n",
      "    server_hostname=server_hostname)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 423, in wrap_socket\n",
      "    session=session\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 870, in _create\n",
      "    self.do_handshake()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 1139, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "socket.timeout: _ssl.c:1059: The handshake operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 355, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1360, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1319, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error _ssl.c:1059: The handshake operation timed out>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 126, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\osm.py\", line 406, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 378, in _call_geocoder\n",
      "    raise GeocoderTimedOut('Service timed out')\n",
      "geopy.exc.GeocoderTimedOut: Service timed out\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('Puerto Rico',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1317, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1244, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1290, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1239, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1414, in connect\n",
      "    server_hostname=server_hostname)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 423, in wrap_socket\n",
      "    session=session\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 870, in _create\n",
      "    self.do_handshake()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 1139, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "socket.timeout: _ssl.c:1059: The handshake operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 355, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1360, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1319, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error _ssl.c:1059: The handshake operation timed out>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 126, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\osm.py\", line 406, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 378, in _call_geocoder\n",
      "    raise GeocoderTimedOut('Service timed out')\n",
      "geopy.exc.GeocoderTimedOut: Service timed out\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('Puerto Rico',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1317, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1244, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1290, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1239, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1414, in connect\n",
      "    server_hostname=server_hostname)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 423, in wrap_socket\n",
      "    session=session\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 870, in _create\n",
      "    self.do_handshake()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 1139, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "socket.timeout: _ssl.c:1059: The handshake operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 355, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1360, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1319, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error _ssl.c:1059: The handshake operation timed out>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 126, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\osm.py\", line 406, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 378, in _call_geocoder\n",
      "    raise GeocoderTimedOut('Service timed out')\n",
      "geopy.exc.GeocoderTimedOut: Service timed out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('The pool of life.',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1317, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1244, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1290, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1239, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1414, in connect\n",
      "    server_hostname=server_hostname)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 423, in wrap_socket\n",
      "    session=session\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 870, in _create\n",
      "    self.do_handshake()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 1139, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "socket.timeout: _ssl.c:1059: The handshake operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 355, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1360, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1319, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error _ssl.c:1059: The handshake operation timed out>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 126, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\osm.py\", line 406, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 378, in _call_geocoder\n",
      "    raise GeocoderTimedOut('Service timed out')\n",
      "geopy.exc.GeocoderTimedOut: Service timed out\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('The pool of life.',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1317, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1244, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1290, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1239, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1414, in connect\n",
      "    server_hostname=server_hostname)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 423, in wrap_socket\n",
      "    session=session\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 870, in _create\n",
      "    self.do_handshake()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 1139, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "socket.timeout: _ssl.c:1059: The handshake operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 355, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1360, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1319, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error _ssl.c:1059: The handshake operation timed out>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 126, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\osm.py\", line 406, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 378, in _call_geocoder\n",
      "    raise GeocoderTimedOut('Service timed out')\n",
      "geopy.exc.GeocoderTimedOut: Service timed out\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('The pool of life.',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1317, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1244, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1290, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1239, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1414, in connect\n",
      "    server_hostname=server_hostname)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 423, in wrap_socket\n",
      "    session=session\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 870, in _create\n",
      "    self.do_handshake()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 1139, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "socket.timeout: _ssl.c:1059: The handshake operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 355, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1360, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1319, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error _ssl.c:1059: The handshake operation timed out>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 126, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\osm.py\", line 406, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 378, in _call_geocoder\n",
      "    raise GeocoderTimedOut('Service timed out')\n",
      "geopy.exc.GeocoderTimedOut: Service timed out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('North Carolina, USA',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1317, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1244, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1290, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1239, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1406, in connect\n",
      "    super().connect()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 938, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\socket.py\", line 727, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\socket.py\", line 716, in create_connection\n",
      "    sock.connect(sa)\n",
      "socket.timeout: timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 355, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1360, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1319, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error timed out>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 126, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\osm.py\", line 406, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 378, in _call_geocoder\n",
      "    raise GeocoderTimedOut('Service timed out')\n",
      "geopy.exc.GeocoderTimedOut: Service timed out\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('North Carolina, USA',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1317, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1244, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1290, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1239, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1414, in connect\n",
      "    server_hostname=server_hostname)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 423, in wrap_socket\n",
      "    session=session\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 870, in _create\n",
      "    self.do_handshake()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 1139, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "socket.timeout: _ssl.c:1059: The handshake operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 355, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1360, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1319, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error _ssl.c:1059: The handshake operation timed out>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 126, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\osm.py\", line 406, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 378, in _call_geocoder\n",
      "    raise GeocoderTimedOut('Service timed out')\n",
      "geopy.exc.GeocoderTimedOut: Service timed out\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*('North Carolina, USA',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1317, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1244, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1290, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1239, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1414, in connect\n",
      "    server_hostname=server_hostname)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 423, in wrap_socket\n",
      "    session=session\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 870, in _create\n",
      "    self.do_handshake()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 1139, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "socket.timeout: _ssl.c:1059: The handshake operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 355, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1360, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1319, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error _ssl.c:1059: The handshake operation timed out>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 126, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\osm.py\", line 406, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 378, in _call_geocoder\n",
      "    raise GeocoderTimedOut('Service timed out')\n",
      "geopy.exc.GeocoderTimedOut: Service timed out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('Brooklyn, New York',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1317, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1244, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1290, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1239, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1414, in connect\n",
      "    server_hostname=server_hostname)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 423, in wrap_socket\n",
      "    session=session\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 870, in _create\n",
      "    self.do_handshake()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 1139, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "socket.timeout: _ssl.c:1059: The handshake operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 355, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1360, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1319, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error _ssl.c:1059: The handshake operation timed out>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 126, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\osm.py\", line 406, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 378, in _call_geocoder\n",
      "    raise GeocoderTimedOut('Service timed out')\n",
      "geopy.exc.GeocoderTimedOut: Service timed out\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('Brooklyn, New York',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1317, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1244, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1290, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1239, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1406, in connect\n",
      "    super().connect()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 938, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\socket.py\", line 727, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\socket.py\", line 716, in create_connection\n",
      "    sock.connect(sa)\n",
      "socket.timeout: timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 355, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1360, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1319, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error timed out>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 126, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\osm.py\", line 406, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 378, in _call_geocoder\n",
      "    raise GeocoderTimedOut('Service timed out')\n",
      "geopy.exc.GeocoderTimedOut: Service timed out\n",
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('Occoquan, VA',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1317, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1244, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1290, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1239, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1414, in connect\n",
      "    server_hostname=server_hostname)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 423, in wrap_socket\n",
      "    session=session\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 870, in _create\n",
      "    self.do_handshake()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 1139, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "socket.timeout: _ssl.c:1059: The handshake operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 355, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1360, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1319, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error _ssl.c:1059: The handshake operation timed out>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 126, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\osm.py\", line 406, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 378, in _call_geocoder\n",
      "    raise GeocoderTimedOut('Service timed out')\n",
      "geopy.exc.GeocoderTimedOut: Service timed out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*('Occoquan, VA',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1317, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1244, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1290, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1239, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\http\\client.py\", line 1414, in connect\n",
      "    server_hostname=server_hostname)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 423, in wrap_socket\n",
      "    session=session\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 870, in _create\n",
      "    self.do_handshake()\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\ssl.py\", line 1139, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "socket.timeout: _ssl.c:1059: The handshake operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 355, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1360, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\urllib\\request.py\", line 1319, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error _ssl.c:1059: The handshake operation timed out>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 126, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\osm.py\", line 406, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"C:\\Users\\sajja\\Anaconda3\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 378, in _call_geocoder\n",
      "    raise GeocoderTimedOut('Service timed out')\n",
      "geopy.exc.GeocoderTimedOut: Service timed out\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None #to not get chained_assignment warning\n",
    "dftest['location2'] = dftest['location'].apply(geocode) #Performing the geocoding and storing the value in a new column,\n",
    "                                                 # We use the .apply function in pandas and pass the geocode function in it \n",
    "\n",
    "#This step will take a long time, so to test, use a small data set\n",
    "#There might also be a 'Service Time Out error' depening on the time the request is being made and the server load on the geocoder server\n",
    "#During the day chances of getting the service time out error is high but eventually the geocoder will collect the coordinates, if it doesnt, run it at a later time or during the night when the server load is low to get the output\n",
    "#The geocoder server being down might also cause issues\n",
    "#The geocoder will eventually return the coordinates of all the locations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest['point'] = dftest['location2'].apply(lambda loc: tuple(loc.point) if loc else None)\n",
    "#geopy has a function .point which returns a tuple of latittude,longitutde and altitude of the location, we store this tuple in a new column \n",
    "#We use a small lambda function which iterates over every  value in location2 column and returns the tuple of lat,long and alt\n",
    "#As some user locations are not actual locations, if geopy can't find the coordinates, it will insert None in its place\n",
    "#Geopy Documentation: https://geopy.readthedocs.io/en/1.10.0/   Geocode with Python: https://towardsdatascience.com/geocode-with-python-161ec1e62b89\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = dftest.dropna(how='any',axis=0)#Removing the None valuess in the dataframe (as unrecognizable locations are assigned None values)\n",
    "dftest.isna().sum() #Verifying that there are no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dftest[['latitude', 'longitude', 'altitude']] = pd.DataFrame(dftest['point'].tolist(), index=dftest.index)\n",
    "#Changing the values in point column to a list and splitting them into three columns (latitude, longitude and altitude)\n",
    "dftest #sample df after geocoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Visualization (Part 1)\n",
    "### Here I will plot the tweets on a map based on the location of the user who tweeted a particular tweet\n",
    "\n",
    "I used the folium map package for printing maps\n",
    "\n",
    "https://python-visualization.github.io/folium/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.to_csv('cleanedlocations.csv')\n",
    "df1 = pd.read_csv('cleanedlocations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium #Importing the folium package\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the map outline \n",
    "map1 = folium.Map(\n",
    "    tiles='cartodbpositron', #Tiles is the type of the map we want to print as the output \n",
    "    zoom_start=12, #Zoom_start lets us choose how zoomed in we want the initial map to appear\n",
    ")\n",
    "\n",
    "#Assigning the points to the map based on the latitude and longitude from the dataframe \n",
    "df1.apply(lambda row:folium.CircleMarker(location=[row[\"latitude\"], row[\"longitude\"]], radius = 5).add_to(map1), axis=1)\n",
    "#Creating a lambda function which iterates through all the lat and long from the df and assigns each value to\n",
    "#folium.CircleMarker which is an inbuilt function in folium, used it to specify points on a map and used radius to specify radius of \n",
    "#points then used add_to to add that point on the map\n",
    "map1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most of the tweets were from America and United Kingdom, In Asia, most of the tweets seem to originate from India which can be due the population of India."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now I will cluster the tweets based on thier area which also shows the number of tweets for a particular cluster\n",
    "\n",
    "You can also zoom in to see smaller clusters based on area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = df1[['latitude', 'longitude']] #creating a new df with only the lat and long of tweets\n",
    "locationlist = locations.values.tolist() #Creating a list of each lat long pair for plotting \n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium.plugins import MarkerCluster #MarkerCluster is a function which clusters the points in a map based on the vicinity \n",
    "#of points from each other and provides a better visualization\n",
    "map = folium.Map(\n",
    "    tiles='cartodbpositron',\n",
    "    zoom_start=12,\n",
    ") #initializing a blank map\n",
    "\n",
    "marker_cluster = MarkerCluster().add_to(map) #initializing the cluster function \n",
    "\n",
    "for point in range(0, len(locationlist)): #iterating through every lat-long on the list\n",
    "    folium.CircleMarker(locationlist[point]).add_to(marker_cluster) #Adding points on the map using the MarkerCluster function\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see out of all the tweets, 619 tweets were from North America, 381 from Europe, 106 from Asia, 50 from Africa and 21 from Oceanic region.\n",
    "\n",
    "This map gives us a general understanding of where people tweet from. There are some outliers in this code as the geocoder couldn't accurately extract the coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization (Part 2) - Text Analysis \n",
    "### Text preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords #importing stopwords for tweets text preprocessing \n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk.sentiment.vader as vd #using the vader lexicon for sentiment analysis \n",
    "from nltk import download\n",
    "download('vader_lexicon')\n",
    "from nltk.tokenize import word_tokenize\n",
    "swords = stopwords.words('english') #assigning the english stopwords to variable swords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Using regex to clean and then split each tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['processed_text'] = df1['text'].str.lower()\\\n",
    "          .str.replace('(@[a-z0-9]+)\\w+',' ')\\\n",
    "          .str.replace('(http\\S+)', ' ')\\\n",
    "          .str.replace('([^0-9a-z \\t])',' ')\\\n",
    "          .str.replace(' +',' ')\\\n",
    "          .apply(lambda x: [i for i in x.split() if not i in swords])\n",
    "    \n",
    "    \n",
    "#Coverting all tweets to lowercase   \n",
    "#Replacing any twitter usernames in the tweet starting with @\n",
    "#Replacing all the links in the tweets \n",
    "#Replacing non alphanumeric text\n",
    "#Replacing unnecessary blank spaces \n",
    "#Creating a lambda function which splits each word in a sentence by using .split function and only stores the word \n",
    "#which is not in the list of stopwords https://medium.com/analytics-vidhya/exploring-twitter-data-using-python-af1287ee65f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Porter Stemming of cleaned tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer() #Initializing the PorterStemmer \n",
    "df1['stemmed'] = df1['processed_text'].apply(lambda x: [ps.stem(i) for i in x if i != ''])\n",
    "#Creating a new column for stemmed sentences, then we create a lambda function which iterateres through every word in a \n",
    "#sentence and perform the stemming function on the word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1: WordCloud\n",
    "Now we will create a wordcloud to see have a pictoral representation of the most used words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigstring = df1['processed_text'].apply(lambda x: ' '.join(x)).str.cat(sep=' ')\n",
    "#using a lambda function to iterate over every preprocessed tweet and using .cat function to concatenate each word and store it\n",
    "#in one long string for the wordcloud \n",
    "\n",
    "plt.figure(figsize=(20,10),facecolor='k' ) #Initializing  the figure size\n",
    "plt.tight_layout(pad=0)\n",
    "wordcloud = WordCloud(                 #initializing the wordcloud \n",
    "                          background_color='blacK', #setting backgroud color \n",
    "                          collocations=False, #Setting this False as we dont want it to include bigrams \n",
    "                          width=1600,\n",
    "                          height=800 #setting width and height of the wordlcoud \n",
    "                         ).generate(bigstring) #passing the long string whose wordcloud we want to generate \n",
    "plt.axis('off') #Removing the axis around the plot as it is not required \n",
    "plt.imshow(wordcloud) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected coronavirus will be the most used word,but after that surpirsingly trump is the most used word, he is always in the news no matter what the topic is\n",
    "\n",
    "Italy is also a commonly used term as it is one of the most affected area by coronavirus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Most user mentions \n",
    "Now we will check that which user has the most mentions in tweets regarding coronavirus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.grid(False)\n",
    "\n",
    "plt.suptitle('Top 10 Most User Mentions', fontsize=14)\n",
    "df1['text'].str\\\n",
    "          .findall('(@[A-Za-z0-9]+)')\\\n",
    "          .apply(lambda x: pd.value_counts(x))\\\n",
    "          .sum(axis=0)\\\n",
    "          .sort_values(ascending=False)[:10]\\\n",
    "          .plot(kind='bar')\n",
    "#we will search the text column as the processed_text has this information removed \n",
    "#We will find every occurence of a user by using str.findall by checking words beginning with @\n",
    "#findall returns a list of string for each occurence (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.findall.html)\n",
    "#Then we create a lambda function where we use value_counts to count the words in each tweet and store it in a df where columnnames are each mentioned user, we do this for all tweets\n",
    "#Then we sum it accross all columns \n",
    "#Then we sort it and select the 10 most mentioned users and plot it in a bar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we can see Donald Trump was mention the most even in tweets regarding coronavirus.\n",
    "\n",
    "Another surprising thing to see is that PerilofAfrica which is a very small African news page is the second most mentioned user handle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Most used Hashtags\n",
    "Now we will find the most used hashtags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #importing regex to find hashtags \n",
    "hashtags = df1['text'].apply(lambda x: pd.value_counts(re.findall('(#\\w+)', x.lower() )))\\\n",
    "                     .sum(axis=0)\\\n",
    "                     .sort_values(ascending=False)\n",
    "#creating a new df where use not not processed text to find the most hashtag occurences\n",
    "#Creating a lambda function where we find occurences of all the words starting with # and convert it to lowercase for consistency\n",
    "#Then sum them column wise and and sort them in descending order\n",
    "hashtags.columns = ['hashtag','occurences'] #renaming the columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hashtags[:8].plot(kind='bar',y='occurences',x='hashtag') #creating the bar okit \n",
    "plt.grid(False)\n",
    "plt.suptitle('Top 8 most used hashtags', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected coronavirus and covid19 are the most used hashtags, a funny observation is that some users are confusing the 19 in covid19 as the year 2019 and using it in hashtags\n",
    "\n",
    "Italy, China and Iran were the most affected countries during the time of collection of tweets hence they had the highest number of used hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Most used words in tweets regariding coroavirus\n",
    "Now we will find which words are used the most in tweets related to coronavirus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = df1['processed_text'].apply(lambda y: pd.value_counts(re.findall('([\\s]\\w+[\\s])',' '.join(y))))\\\n",
    "                            .sum(axis=0)\\\n",
    "                            .sort_values(ascending=False)\n",
    "#we use the processed tweets as we want to do a word count for each word, we create a lambda function where we do a value count\n",
    "#for each word, we search for distinct words using regex, the search is done based on spaces\"[\\s]\" between each word\n",
    "#then we sum each word column wise and sort it in descending order\n",
    "\n",
    "words.columns = ['word','occurences'] #Renaming the columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[:10].plot(kind='bar',y='occurences',x='word') #creating the bar plot \n",
    "plt.grid(False)\n",
    "plt.suptitle('Top 10 most used words', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coronavirus is the most used word but again trump is present in the tweets regarding coronavirus, looks like trump is at the centre of every major topic happpening around the world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Sentiment Analysis \n",
    "Now we will perform sentiment analysis to check if tweets about coronavirus are mainly negative or positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the sentiment analyzer \n",
    "sia = vd.SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['sentiment_score'] = df1['processed_text'].apply(lambda x: sum([ sia.polarity_scores(i)['compound'] for i in word_tokenize( ' '.join(x) )]) )\n",
    "#we create a lambda function where We use tokenizer to tokenize the words so that we can feed one word to the sentiment analyzer\n",
    "#at a time and them sum up the sentiment score of each word for a particular tweet and store it in a new column\n",
    "\n",
    "df1['sentiment_score'] = df1['sentiment_score'].apply(lambda x: round(x,)) #we then round off the sentiment scores for better visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we perform binning so that we can visualize this data in a better way\n",
    "sent_classification = pd.cut(df1['sentiment_score'],\\\n",
    "          [-3,-1.2, 0, 1.2 , 3],\\\n",
    "          right=True,\\\n",
    "          include_lowest=True,\\\n",
    "          labels=['strongly negative', 'negative', 'positive', 'strongly positive']) #assigning labels to corresponding sentiment\n",
    "#We store this value in a new variable sent_classification for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bar Graph showing number of tweets based on thier senitment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5)) #make it smaller this time\n",
    "sent_classification.value_counts().plot(kind='bar')\n",
    "plt.grid(False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see most of the tweets are negative which is understandable as coronavirus has a negative conscience around it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Visualization\n",
    "#### Now we will try to plot tweets based on thier sentiment to see from where people are tweeting positive/negative things regarding coronavirus\n",
    "\n",
    "The inspiration for this visualization came after I read about a research paper in my Text Analysis Module where the authors predicted the path of a hurricane based on the location of tweets.\n",
    "\n",
    "My idea was to visualize which areas in the world are tweeting postive tweets about coronavirus and which areas are tweeting negative tweets, this will give us a general understanding of high affected areas and areas which are recovering.\n",
    "\n",
    "This reseach paper also proposes how twitter data can be used for disaster management\n",
    "https://link.springer.com/article/10.1007/s10479-017-2522-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function where we assign color to each sentiment\n",
    "#Red to negative tweets, green to positive tweets and darkblue to neutral tweets\n",
    "def sentimentcolors(counter):\n",
    "    if counter['sentiment_score'] == -3:\n",
    "        return 'red'\n",
    "    elif counter['sentiment_score'] == -2:\n",
    "        return 'red'\n",
    "    elif counter['sentiment_score'] == -1:\n",
    "        return 'red'\n",
    "    elif counter['sentiment_score'] == 1:\n",
    "        return 'green'\n",
    "    elif counter['sentiment_score'] == 2:\n",
    "        return 'green'\n",
    "    else:\n",
    "        return 'darkblue'\n",
    "    \n",
    "df1[\"color\"] = df1.apply(sentimentcolors, axis=1) #Color coding each tweet based on its sentiment and storing it in a new column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new df which only stores the lat, long and the color of each sentiment which is required to plot the map\n",
    "sentidf = df1[['latitude', 'longitude', 'color']]\n",
    "sentidf = sentidf[sentidf.color != 'darkblue'] #Removing all the entries which have a neutral polatrity as we only want the\n",
    "#positive and negative tweets \n",
    "sentidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = folium.Map(\n",
    "    tiles='cartodbpositron',\n",
    "    zoom_start=12,\n",
    ") #initializing the map\n",
    "\n",
    "for index, row in sentidf.iterrows(): #using iterrows to iterate through the df\n",
    "    folium.CircleMarker([row['latitude'], row['longitude']],\n",
    "                    radius=1, color=row['color']).add_to(map)\n",
    "#Circle marker has a argument color which can be used to assign color to the point on the map, we use the color value of each\n",
    "#lat-long pair and plot the point according to that\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see most of the tweets in America have a negative sentiment, surprisingly many tweets in UK had a positive Sentiment.\n",
    "\n",
    "In Ireland, everyone had only negative things to say about coronavirus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "As I have used user location based on what they set in thier profile, the results are not a very accurate representation of the tweet location but for a large dataset it gives an overall accurate result. To make this more robust, we can use the co-odrinates of the location of the user from where they are currently tweeting (but this co-ordinate is generally disabled and not availabe) but these coordinates are not readily available.\n",
    "During a disaster, this type of location + sentiment analysis can be used for a particular location and check the sentiments to see which area is worst hit by the disaster and"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
